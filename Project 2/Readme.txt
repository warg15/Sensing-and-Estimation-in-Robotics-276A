ECE 276A – SLAM on THOR RobotThis project is intended to take as an input a dataset from the THOR robot, and use it to perform simultaneous localization and mapping on 5 different environments the robot was placed in. These datasets can be found in the attached files. The datasets contain lidar scans, odometry of the robot, information on the pitch and yaw of the robot’s head during runtime, and images from a camera on the robot’s head. This Python code file takes this data, and for each of the maps, performs SLAM to correct the errors in the odometry data – thus getting the true robot position, while mapping the environment the robot is in. To accomplish this, the code uses a series of linear transforms to convert all sensor measurements to the world frame, and a particle filter to obtain the robot’s true position by introducing noise to the odometry and evaluating the correctness of each of many possible robot states.This project exists to satisfy the requirement of UC San Diego class ECE 276A, Project 2. The purpose of this project and the class as a whole is for the student to learn and get familiar with performing SLAM on a real world robotic system. Specifically, this project focuses on the aspects of SLAM that include transforming the sensor data, and accomplishes accurate localization with a lidar filter.Build statusThis project has been completed and tested. It can be seen in the accompanying project report that the program completed SLAM on the robot datasets successfully. This included showing a vast improvement over using only a dead reckoning approach. Additionally, some of the code in this project may be adaptable to other projects, such as functions that transform frames, as well as the algorithm coded to update the particles in the particle filter.Code styleThe goal of the student was to code this project in the Python Pep8 style, according to python.org, however, as this is project is the first time the student has coded in Python, there are some styling errors in the code that the student will look to resolve in later versions.Tech/framework usedFor the first part of this project, converting all the data to useable quantities, the main tech framework used was creating rotation and transformation matrices. This was done by following the information laid out in the UCSD ECE 276A lecture slides, which are referenced in the included project report. The numpy library was used extensively in all parts of this project for its ability to easily and quickly reference, perform computations on, and handle large amounts of data in arrays.For the second part of this project, implementing a particle filter, the theory used was also described in the UCSD ECE 276A lecture. The student found through testing, however, that the provided correlation function was too slow to be truly useable, so the student wrote his own, which can be found in a simple loop which loops through all particles at each time index. The other main theoretical piece used in the particle filter was the use of stratified resampling; again described in the lecture slides.Code ExampleThe easiest way to run this example code is to set the first 3 lines in the main function to load data for “lidar0”. This will allow the user to run SLAM on that dataset and get the occupancy grid outputted to their console. The user is then free to change the program to their liking – changing the way the result is displayed, or the number of particles or lidar scans used, but this does come with the warning that changing these parameters may cause the program to function incorrectly.InstallationTo install, please make sure the user is running Python 3.7.0 or later and has OpenCV cv2 installed. Next, the user must be sure to place the included datasets for lidar readings and joint readings in the same directory as this code is being saved. After setting the desired map as described in the code example, the user can run the program to perform SLAM. The user can also input their own data, provided it is in the same format as the included datasets (meaning essentially it must be from the same robot to take advantage of the tuned noise in the particle filter), and this program will be able to handle it and perform SLAM – its parameters are set-up to give good overall performance for any map, not finely tuned to one specific map.High Level Description of functions and pseudo code of main loopLidar2cartesian: Pulls the lidar scan and from the given time index and coverts it into cartesian coordinates and returns these in an array containing all scans for that time indexLidar2head: Includes the simple transformation for taking in lidar scan coordinates and going from lidar sensor to head and transforms all the lidar scan coordinates given to it in an array into the head frame and returns them in an arrayfindR:Purpose is to find a rotation matrix given values of the angles psi, theta, and phi. Returns the rotation matrix in a 3x3 array.Head2body:Purpose is to transform lidar scan coordinates passed to it from head frame to body frame. To do this, it pulls the head and neck angles for the given time index from the dataset given. Uses findR and the known head to body translation to create a transformation matrix and returns the array of lidar coordinates transformed into body frameBody2world:Purpose is to transform array of lidar coordinates to world frame form body. Take in robot state in order to use findR to calculate the transformation matrix and the robot’s x and y coordinates to find the translation. Returns lidar scans transformed into the world frame.Meters2cells:Takes as input coordinates in the world frame in meters and the arrays defining the meter coordinates of each cell. It finds out which cells the given coordinates should be in and returns the x and y cell numbers. Useful to single pairs of coordinates into cells.Meters2cellsVector:Takes an array of x and y coordinates in meters and returns an array of the x and y cell coordinates. Uses code from the p2.utils functions provided with the project.  Useful for converting an array of lidar scans from meters to cells.Cells2meters:Takes the x and y coordinates of a cell and will return the approximate x and y coordinates in meters. Was not used in any of the main parts of the program but was created in case a need arose as calling it is more convenient than writing the code over and over.robotState2Cells:Purpose is to convert a robot state with x, y and theta values into cells. Differs from meters2cells, as it can handle being passed the entire robot state, with theta, and converts the x and y coordinates and then returns a vector with x, y, and theta included.robotUpdateState:Purpose is to add the delta pose of the given time index to the robot state that is passed to it. Pulls the delta pose information directly from the imported dataset using the given time stamp. Returns the updated robot state. Useful when doing dead reckoning.mappingSmart:Purpose is to be passed the current time index and robot state and then update the map of the environment, all in one function. This function pulls the lidar scan for the given time period directly from the imported data, and then passes it through the functions above to go from lidar polar coordinates in cartesian, then from lidar sensor to head, then from head to body, and then from body to world frame. It then converts the lidar readings in meters into cells using the above function meters2cellsVector. The function then creates a temporary map the same size as the actual map, and relies on the cv2 function drawContours to handle putting the lidar scans onto the temporary map. This requires that the lidar scans, which are coordinates of the countours given to drawContours are in the form of a list of arrays of type int32, so the code in this function goes through some trivial conversions to achieve this form. Then drawContours is called with the lidar scans passed as coordinates to the contours and the last argument as -1, meaning the function is to fill in the cells in the area up to and including the lidar scans with the subtracted log odds. Then, drawContours is called again with the lidar scans passed as coordinates to the contours and the last argument as 1, meaning the function is to replace the values only at the cells where the lidar scan hits with the positive log odds, thus creating a temporary map with the positive and negative log odds on it. This temporary map is then added to the main map, updating the log odds with the current lidar scan.updateParticlesThe purpose of this function is to update the particles with both the delta pose and the noise required for a correct particle filter. The function is passed the array containing all the particles states and weights, in order to efficiently update them in vector form. Updating the delta pose works in much the same way as the robotUpdateState function above. Then noise is only added to the particles if the robot moves in that time step. This is explained in depth in the report. Then the updated array of particles is returned.Pseudo Code for main function.Note that some of the following code is adapted and borrowed from the p2_utils.py and load_data.py as the student preferred to put all of the code in one file rather than calling functions from other filesLoad the joint data for the desired datasetLoad the lidar data for the desired datasetCreate a map dictionaryAdd entry for resolutionAdd entry for how far negative the ‘x’ coordinates go in metersAdd entry for how far negative the ‘y’ coordinates go in metersAdd entry for how far positive the ‘x’ coordinates go in metersAdd entry for how far positive the ‘y’ coordinates go in metersCalculate the map x size in cells and add to an entryCalculate the map y size in cells and add to an entryCreate a map entry of given size and all zerosCreate an array that lists all the x coordinates in meters of the x cells, which the entry      corresponds to the cellCreate an array that lists all the y coordinates in meters of the x cells, which the entry      corresponds to the cell      Get the map dimension (only square maps were used)Clear the map in the MAP dictionaryCreate an array save the first delta pose inCreate an array for robot state in meters, initialized to 0Create an array for the robot state in cells and convert the state to cellsCreate an array to store each robot state and store the first oneSet Lidar TrustSet number of particlesCreate an array for all the particles to be stored inInitialize the particle weightsFind indices of max for every column in particlesGet the index for particle of max weightSet robot state as particle of max weightMap the first lidar scan from that particleInitialize array to save particle correlations (good for debugging)Create variable to count number of times particles are resampled (good for debugging)Create variable that determines how often lidar scans are used (every scan, every 5 scans, etc)Create variable that determines how often current occupancy grid map is saved. (picSave)For every lidar scan:	If it’s the picSave-th scan:		Find map cells that are positive		Find map cells that are negative		Get map size      Create a pseudo map for saving binary occupancy grid      Set positive cells to 1      Set negative cells to -1      Convert stored robot states to type int      Set all cells the robot has been in to 2      Show the map      Save the map      	If it’s the skipScan-th scan:		Create array to store particle correlations		Find map cells that are positive		Find map cells that are negative		Get map size      Create a pseudo map for finding correlation      Set positive cells to 1      Set negative cells to 0				Get lidar state in cartesian		Convert to head frame		Convert to body frame		For all particles:			Get the current particle			Convert lidar scan from body to world (using particle’s coordinates)			Get the cells the lidar scan hit						Convert x cell coordinates to int32      Convert y cell coordinates to int32      Recreate cells array as type int32      Save the correlation for the current particle and the current time index by summing the value of all cells the scan hits (since it’s a binary map, occupied cells are 1 so this returns number of occupied cells hit by the lidar scan if the robot was in its current particle position)		Take softmax of the correlations for all particles		Assign the correlations to all particles				Find indices of max for every column in particles      Get the index for particle of max weight      Set robot state as particle of max weight      Convert state in meters to cells      Save the robot state      Call MappingSmart to update the map      Calcualte n-effective      Set value of n-threshold            If n-effective is less than or equal to n-threshold:      	Increment count resample      	Initialize variables for stratified resampling algorithm      	Create an array to store new particles      	      For the range of all particles:      	This is the stratified resampling algorithm in slides      Set value of b      While b > c:      	Increment j      	Add particle weight to c      Assign x value to new particle      Assign y value to new particle      Assign theta value to new particle      Assign weight to particle			Set new particles as current particlesFind map cells that are positiveFind map cells that are negativeGet map sizeCreate a pseudo map for binary occupancy gridSet positive cells to 1Set negative cells to -1Convert stored robot states to type intSet all cells the robot has been in to 2Show the mapCreate color barSave the mapDisplay map in console      	Show log odds mapCreate color barSave the mapDisplay in consoleSave the map array	      	Note from the studentMuch of the main loop could have been parsed off into functions, however the student was tuning parameters and trying different ways to resample and find correlation so the code was left in the main loop, and the program works well and is tune-able in that configuration so the student elected to leave it in that configuration and explain it in the pseudo code above.Please also note that the code is commented in depth as well, as it is the goal of the student that the code be easy to understand for the user.CreditsECE 276A Course Website: https://natanaso.github.io/ece276a/ECE 276A Piazza: https://piazza.com/class/k4tbsww5fuu4y0?cid=34#Study Group: Roumen Guha, Maria Fatima, Stephen West